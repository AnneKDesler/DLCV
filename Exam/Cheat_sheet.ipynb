{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from IPython import display\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a convolutional kernel to an image matrix\n",
    "def convolve2d(X, W):\n",
    "    h, w = X.shape\n",
    "    m, n = W.shape\n",
    "    Y = np.zeros((h-m+1, w-n+1))\n",
    "    for i in range(h-m+1):\n",
    "        for j in range(w-n+1):\n",
    "            Y[i][j] = np.sum(X[i:i+m, j:j+n]*W)\n",
    "    return Y\n",
    "\n",
    "# apply a max pooling to an image matrix\n",
    "def maxpool2d(X, size=2):\n",
    "    h, w = X.shape\n",
    "    Y = np.zeros((h//size, w//size))\n",
    "    for i in range(h//size):\n",
    "        for j in range(w//size):\n",
    "            Y[i][j] = np.max(X[i*size:i*size+size, j*size:j*size+size])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5]\n",
      " [ 6  7  8  9 10]\n",
      " [ 6  7  8  9 10]\n",
      " [16 17 18 19 20]\n",
      " [21 22 23 24 25]]\n",
      "[[8. 8. 8.]\n",
      " [8. 8. 8.]\n",
      " [8. 8. 8.]]\n",
      "[[ 7.  9.]\n",
      " [17. 19.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10], [6, 7, 8, 9, 10], [16, 17, 18, 19, 20], [21, 22, 23, 24, 25]])\n",
    "W = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "print(X)\n",
    "Y = convolve2d(X, W)\n",
    "print(Y)\n",
    "Y = maxpool2d(X)\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.,  2.,  3.,  4.,  5.],\n",
      "          [ 6.,  7.,  8.,  9., 10.],\n",
      "          [ 6.,  7.,  8.,  9., 10.],\n",
      "          [16., 17., 18., 19., 20.],\n",
      "          [21., 22., 23., 24., 25.]]]])\n",
      "tensor([[[[8., 8., 8.],\n",
      "          [8., 8., 8.],\n",
      "          [8., 8., 8.]]]])\n",
      "tensor([[[[ -1.,  -2.,  -2.,  -2.,  -2.,   4.,   5.],\n",
      "          [ -8., -11.,  -6.,  -6.,  -6.,  17.,  20.],\n",
      "          [-19., -23.,  -8.,  -8.,  -8.,  31.,  35.],\n",
      "          [-34., -38.,  -8.,  -8.,  -8.,  46.,  50.],\n",
      "          [-59., -63.,  -8.,  -8.,  -8.,  71.,  75.],\n",
      "          [-58., -61.,  -6.,  -6.,  -6.,  67.,  70.],\n",
      "          [-21., -22.,  -2.,  -2.,  -2.,  24.,  25.]]]])\n",
      "tensor([[[[-11.,  -6.,  -6.,  -6.,  17.],\n",
      "          [-23.,  -8.,  -8.,  -8.,  31.],\n",
      "          [-38.,  -8.,  -8.,  -8.,  46.],\n",
      "          [-63.,  -8.,  -8.,  -8.,  71.],\n",
      "          [-61.,  -6.,  -6.,  -6.,  67.]]]])\n",
      "tensor([[[[ -1.,   0.,  -1.,   0.,  -1.,   0.,  -1.,   0.,  -1.,   0.,   5.,\n",
      "             0.],\n",
      "          [ -2.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  10.,\n",
      "             0.],\n",
      "          [ -7.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  15.,\n",
      "             0.],\n",
      "          [-12.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  20.,\n",
      "             0.],\n",
      "          [-12.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  20.,\n",
      "             0.],\n",
      "          [-12.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  20.,\n",
      "             0.],\n",
      "          [-22.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  30.,\n",
      "             0.],\n",
      "          [-32.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  40.,\n",
      "             0.],\n",
      "          [-37.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  45.,\n",
      "             0.],\n",
      "          [-42.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  -2.,   0.,  50.,\n",
      "             0.],\n",
      "          [-21.,   0.,  -1.,   0.,  -1.,   0.,  -1.,   0.,  -1.,   0.,  25.,\n",
      "             0.],\n",
      "          [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "             0.]]]])\n",
      "tensor([[[[ 0., -2.,  0., -2.,  0., -2.,  0., -2.,  0., 10.],\n",
      "          [ 0., -2.,  0., -2.,  0., -2.,  0., -2.,  0., 15.],\n",
      "          [ 0., -2.,  0., -2.,  0., -2.,  0., -2.,  0., 20.],\n",
      "          [ 0., -2.,  0., -2.,  0., -2.,  0., -2.,  0., 20.],\n",
      "          [ 0., -2.,  0., -2.,  0., -2.,  0., -2.,  0., 20.],\n",
      "          [ 0., -2.,  0., -2.,  0., -2.,  0., -2.,  0., 30.],\n",
      "          [ 0., -2.,  0., -2.,  0., -2.,  0., -2.,  0., 40.],\n",
      "          [ 0., -2.,  0., -2.,  0., -2.,  0., -2.,  0., 45.],\n",
      "          [ 0., -2.,  0., -2.,  0., -2.,  0., -2.,  0., 50.],\n",
      "          [ 0., -1.,  0., -1.,  0., -1.,  0., -1.,  0., 25.]]]])\n",
      "torch.Size([1, 1, 10, 10])\n",
      "tensor([[[[ 7.,  9.],\n",
      "          [17., 19.]]]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.from_numpy(X).unsqueeze(0).unsqueeze(0).float()\n",
    "W = torch.from_numpy(W).unsqueeze(0).unsqueeze(0).float()\n",
    "print(X)\n",
    "Y = F.conv2d(X, W, bias=None, stride=1, padding=0, dilation=1, groups=1)\n",
    "print(Y)\n",
    "\n",
    "Y = F.conv_transpose2d(X, W, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1)\n",
    "print(Y)\n",
    "\n",
    "\n",
    "Y = F.conv_transpose2d(X, W, bias=None, stride=1, padding=1, output_padding=0, groups=1, dilation=1)\n",
    "print(Y)\n",
    "\n",
    "Y = F.conv_transpose2d(X, W, bias=None, stride=2, padding=0, output_padding=1, groups=1, dilation=1)\n",
    "print(Y)\n",
    "\n",
    "Y = F.conv_transpose2d(X, W, bias=None, stride=2, padding=1, output_padding=1, groups=1, dilation=1)\n",
    "print(Y)\n",
    "print(Y.shape)\n",
    "Y = F.max_pool2d(X, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "print(Y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output dimension of convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function that outputs the dimensions of the output of a convolutional layer\n",
    "def conv_output_shape(h,w, kernel_size=1, stride=1, pad=0, dilation=1):\n",
    "    from math import floor\n",
    "    if type(kernel_size) is not tuple:\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "    h_out = floor(((h + (2 * pad) - (dilation * (kernel_size[0] - 1)) - 1) / stride) + 1)\n",
    "    w_out = floor(((w + (2 * pad) - (dilation * (kernel_size[0] - 1)) - 1) / stride) + 1)\n",
    "    return h_out, w_out\n",
    "\n",
    "def trans_conv_output_shape(h,w, kernel_size=1, stride=1, pad=0, output_padding=0, dilation=1):\n",
    "    from math import floor\n",
    "    if type(kernel_size) is not tuple:\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "    h_out = floor((h-1)*stride - 2*pad + dilation*(kernel_size[0]-1) + output_padding + 1)\n",
    "    w_out = floor((w-1)*stride - 2*pad + dilation*(kernel_size[0]-1) + output_padding + 1)\n",
    "    return h_out, w_out\n",
    "\n",
    "\n",
    "def padding_needed(kernel_size):\n",
    "    if type(kernel_size) is not tuple:\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "    if kernel_size[0]%2 == 0:\n",
    "        pad = (kernel_size[0]-1)//2\n",
    "    else:\n",
    "        pad = kernel_size[0]//2\n",
    "    return pad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.,  2.,  3.,  4.,  5.],\n",
      "          [ 6.,  7.,  8.,  9., 10.],\n",
      "          [ 6.,  7.,  8.,  9., 10.],\n",
      "          [16., 17., 18., 19., 20.],\n",
      "          [21., 22., 23., 24., 25.]]]])\n",
      "torch.Size([1, 1, 5, 5])\n",
      "5 5\n",
      "5 5\n",
      "5 5\n",
      "3 3\n",
      "5 5\n",
      "5 5\n",
      "12 12\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(X.shape)\n",
    "h = X.shape[2]\n",
    "w = X.shape[3]\n",
    "print(h,w)\n",
    "h_out, w_out = conv_output_shape(h,w, kernel_size=1, stride=1, pad=0, dilation=1)\n",
    "print(h_out, w_out)\n",
    "\n",
    "h_out, w_out = conv_output_shape(h,w, kernel_size=3, stride=1, pad=1, dilation=1)\n",
    "print(h_out, w_out)\n",
    "\n",
    "h_out, w_out = conv_output_shape(6,6, kernel_size=2, stride=2, pad=0, dilation=1)\n",
    "print(h_out, w_out)\n",
    "\n",
    "h_out, w_out = trans_conv_output_shape(h,w, kernel_size=1, stride=1, pad=0, output_padding=0, dilation=1)\n",
    "print(h_out, w_out)\n",
    "\n",
    "h_out, w_out = trans_conv_output_shape(h,w, kernel_size=3, stride=1, pad=1, output_padding=0, dilation=1)\n",
    "print(h_out, w_out)\n",
    "\n",
    "h_out, w_out = trans_conv_output_shape(6,6, kernel_size=2, stride=2, pad=0, output_padding=0, dilation=1)\n",
    "print(h_out, w_out)\n",
    "\n",
    "print(padding_needed(3))\n",
    "print(padding_needed(7))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reseptive field \n",
    "Tegn. Start bag fra.\n",
    "\n",
    "function virker ikke! men tror måske den giver størrelsen eller noget, så kan måske bruges lidt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a function that can determinate the reseptive field of a given pixel (x,y), given a list of kernel sizes, strides, paddings and dilations and number of layers\n",
    "# and return the receptive field of the pixel (x,y) as min_x, min_y, max_x, max_y \n",
    "# such that the reseptive field of the pixel (x,y) is the rectangle with corners (min_x, min_y) and (max_x, max_y)\n",
    "def receptive_field(x,y,kernel_size, stride, padding, dilation, layers):\n",
    "    from math import floor\n",
    "    if type(kernel_size) is not list:\n",
    "        kernel_size = [kernel_size]*layers\n",
    "    if type(stride) is not list:\n",
    "        stride = [stride]*layers\n",
    "    if type(padding) is not list:\n",
    "        padding = [padding]*layers\n",
    "    if type(dilation) is not list:\n",
    "        dilation = [dilation]*layers\n",
    "    if len(kernel_size) != layers or len(stride) != layers or len(padding) != layers or len(dilation) != layers:\n",
    "        print(\"Error: The number of layers does not match the number of kernel sizes, strides, paddings and dilations\")\n",
    "        return\n",
    "    min_x = x\n",
    "    min_y = y\n",
    "    max_x = x\n",
    "    max_y = y\n",
    "    for i in range(layers):\n",
    "        min_x = floor((min_x - 1) * stride[i] - 2 * padding[i] + dilation[i] * (kernel_size[i] - 1) + 1)\n",
    "        min_y = floor((min_y - 1) * stride[i] - 2 * padding[i] + dilation[i] * (kernel_size[i] - 1) + 1)\n",
    "        max_x = floor((max_x - 1) * stride[i] - 2 * padding[i] + dilation[i] * (kernel_size[i] - 1) + 1)\n",
    "        max_y = floor((max_y - 1) * stride[i] - 2 * padding[i] + dilation[i] * (kernel_size[i] - 1) + 1)\n",
    "    return min_x, min_y, max_x, max_y\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a function that kan calculate the size of the receptive field\n",
    "def receptive_field_size(kernel_size, stride, padding, dilation, layers):\n",
    "    # the final output size corresponds to the receptive field of the first pixel\n",
    "    from math import floor\n",
    "    if type(kernel_size) is not list:\n",
    "        kernel_size = [kernel_size]*layers\n",
    "    if type(stride) is not list:\n",
    "        stride = [stride]*layers\n",
    "    if type(padding) is not list:\n",
    "        padding = [padding]*layers\n",
    "    if type(dilation) is not list:\n",
    "        dilation = [dilation]*layers\n",
    "    if len(kernel_size) != layers or len(stride) != layers or len(padding) != layers or len(dilation) != layers:\n",
    "        print(\"Error: The number of layers does not match the number of kernel sizes, strides, paddings and dilations\")\n",
    "        return\n",
    "    size = 1\n",
    "    for i in range(layers):\n",
    "        size = floor((size - 1) * stride[i] - 2 * padding[i] + dilation[i] * (kernel_size[i] - 1) + 1)\n",
    "    return size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7, 5, 7)\n",
      "(1, 2, 1, 2)\n",
      "(4, 4, 4, 4)\n",
      "(40, 52, 40, 52)\n"
     ]
    }
   ],
   "source": [
    "rf = receptive_field(1,2,kernel_size=[3,3], stride=[1,2], padding=[0,1], dilation=[1,1], layers=2)\n",
    "print(rf)\n",
    "rf = receptive_field(1,2,kernel_size=[3], stride=[1], padding=[1], dilation=[1], layers=1)\n",
    "print(rf)\n",
    "\n",
    "rf = receptive_field(1,1,kernel_size=[3,2,3,2,3], stride=[1,2,1,2,1], padding=[1,0,1,0,1], dilation=[1,1,1,1,1], layers=5)\n",
    "print(rf)\n",
    "rf = receptive_field(10,13,kernel_size=[3,2,3,2,3], stride=[1,2,1,2,1], padding=[1,0,1,0,1], dilation=[1,1,1,1,1], layers=5)\n",
    "print(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "rf = receptive_field_size(kernel_size=[3,2,3,2,3], stride=[1,2,1,2,1], padding=[1,0,1,0,1], dilation=[1,1,1,1,1], layers=5)\n",
    "print(rf)\n",
    "\n",
    "rf = receptive_field_size(kernel_size=[3,2,3,2,3,2,3,2,3,1], stride=[1,2,1,2,1,2,1,2,1,1], padding=[1,0,1,0,1,0,1,0,1,0], dilation=[1,1,1,1,1,1,1,1,1,1], layers=10)\n",
    "print(rf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00159356 0.03200752 0.08700545 0.23650533 0.64288814]\n",
      "[0.26894142 0.88079708 0.95257413 0.98201379 0.99330715]\n",
      "[0. 2. 3. 4. 5.]\n",
      "tensor([0.0016, 0.0320, 0.0870, 0.2365, 0.6429], dtype=torch.float64)\n",
      "tensor([0.2689, 0.8808, 0.9526, 0.9820, 0.9933], dtype=torch.float64)\n",
      "tensor([0., 2., 3., 4., 5.], dtype=torch.float64)\n",
      "tensor([-0.7616,  0.9640,  0.9951,  0.9993,  0.9999], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-1.,2.,3.,4.,5.])\n",
    "print(softmax(x))\n",
    "print(sigmoid(x))\n",
    "print(relu(x))\n",
    "\n",
    "x = torch.from_numpy(x)\n",
    "print(nn.Softmax(dim=0)(x))\n",
    "print(nn.Sigmoid()(x))\n",
    "print(nn.ReLU()(x))\n",
    "print(nn.Tanh()(x))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(x, y):\n",
    "    return -np.mean(y*np.log(x)+(1-y)*np.log(1-x))\n",
    "\n",
    "def cross_entropy(x, y):\n",
    "    return -np.sum(y*np.log(x))\n",
    "\n",
    "def focal_loss(x, y, gamma=2):\n",
    "    return -np.mean(y*np.power(1-x, gamma)*np.log(x))\n",
    "\n",
    "def binary_focal_loss(y_real, y_pred, gamma=2):\n",
    "    loss = -torch.mean(y_real*(1-y_pred)**gamma*torch.log(y_pred) + (1-y_real)*torch.log(1-y_pred))\n",
    "    return loss\n",
    "\n",
    "#def dice_loss(x, y):\n",
    "#    return -np.mean(2*x*y/(x+y))\n",
    "\n",
    "def dice_loss(y_real, y_pred):\n",
    "    loss = 1 - torch.mean(2*y_real*y_pred+1)/(torch.mean(y_real+y_pred) + 1)\n",
    "    return loss\n",
    "\n",
    "def bce_total_variation(y_real, y_pred):\n",
    "    y_pred2 = F.sigmoid(y_pred)\n",
    "    total_variation = torch.mean(torch.abs(y_pred2[:, :, :, :-1] - y_pred2[:, :, :, 1:])) + torch.mean(torch.abs(y_pred2[:, :, :-1, :] - y_pred2[:, :, 1:, :]))\n",
    "    return bce_loss(y_real, y_pred) + 0.1*total_variation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5472899351247816\n",
      "0.11798933482394172\n",
      "tensor(0.5473, dtype=torch.float64)\n",
      "tensor(0.2533, dtype=torch.float64)\n",
      "2.441784530014455\n",
      "tensor(2.3027, dtype=torch.float64)\n",
      "tensor(2.3027, dtype=torch.float64)\n",
      "tensor(2.4418, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.1,0.2,0.3,0.4,0.5])\n",
    "y = np.array([0.,0.,1.,0.,0.])\n",
    "print(binary_cross_entropy(x,y))\n",
    "print(focal_loss(x,y))\n",
    "\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)\n",
    "print(nn.BCELoss()(x,y))\n",
    "print(dice_loss(x,y))\n",
    "x = np.array([-1.,2.,3.,4.,5.])\n",
    "y = np.array([0.,0.,1.,0.,0.])\n",
    "\n",
    "print(cross_entropy(softmax(x),y))\n",
    "\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)\n",
    "\n",
    "print(nn.BCEWithLogitsLoss()(x,y))\n",
    "print(nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.,1.,1.,1.,1.]))(x,y))\n",
    "\n",
    "print(nn.CrossEntropyLoss()(x,y))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU_bbox(box1,box2,mode=\"xywh\"):\n",
    "    # if mode == \"xyxy\":\n",
    "    # box1 = [x11,y11,x12,y12]\n",
    "    # box2 = [x21,y21,x22,y22]\n",
    "    # elif mode == \"xywh\":\n",
    "    # box1 = [x11,y11,w,h]\n",
    "    # box2 = [x21,y21,w,h]\n",
    "    # returns the intersection over union of\n",
    "    if mode == \"xyxy\":\n",
    "        x11 = box1[0]\n",
    "        y11 = box1[1]\n",
    "        x12 = box1[2]\n",
    "        y12 = box1[3]\n",
    "        w1 = abs(x12 - x11)\n",
    "        h1 = abs(y12 - y11)\n",
    "        x21 = box2[0]\n",
    "        y21 = box2[1]\n",
    "        x22 = box2[2]\n",
    "        y22 = box2[3]\n",
    "        w2 = abs(x22 - x21)\n",
    "        h2 = abs(y22 - y21)\n",
    "    elif mode == \"xywh\":\n",
    "        x11 = box1[0]\n",
    "        y11 = box1[1]\n",
    "        w1 = box1[2]\n",
    "        h1 = box1[3]\n",
    "        x22 = box2[0]\n",
    "        y22 = box2[1]\n",
    "        w2 = box2[2]\n",
    "        h2 = box2[3]\n",
    "    else:\n",
    "        print(\"Error: unknown mode\")\n",
    "        return\n",
    "    # calculate the intersection\n",
    "    xI1 = max(x11, x22)\n",
    "    yI1 = max(y11, y22)\n",
    "    xI2 = min(x11 + w1, x22 + w2)\n",
    "    yI2 = min(y11 + h1, y22 + h2)\n",
    "    interArea = max(0, xI2 - xI1) * max(0, yI2 - yI1)\n",
    "    # calculate the union\n",
    "    boxAArea = w1 * h1\n",
    "    boxBArea = w2 * h2\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def x1y1x2y2_to_x1y1wh(x):\n",
    "    # Convert bounding box format from [x1, y1, x2, y2] to [x1, y1, w ,h]\n",
    "    y = x.clone()\n",
    "    y[:, 0] = x[:, 0]\n",
    "    y[:, 1] = x[:, 1]\n",
    "    x1 = x[:, 0]\n",
    "    y1 = x[:, 1]\n",
    "    x2 = x[:, 2]\n",
    "    y2 = x[:, 3]\n",
    "    w = abs(x2 - x1)\n",
    "    h = abs(y2 - y1)\n",
    "    y[:, 2] = w\n",
    "    y[:, 3] = h\n",
    "    return y\n",
    "\n",
    "def x1y1wh_to_x1y1x2y2(x):\n",
    "    # Convert bounding box\n",
    "    y = x.clone()\n",
    "    y[:, 0] = x[:, 0]\n",
    "    y[:, 1] = x[:, 1]\n",
    "    x1 = x[:, 0]\n",
    "    y1 = x[:, 1]\n",
    "    w = x[:, 2]\n",
    "    h = x[:, 3]\n",
    "    x2 = x1 + w\n",
    "    y2 = y1 + h\n",
    "    y[:, 2] = x2\n",
    "    y[:, 3] = y2\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "def xyxy2xywh(x):\n",
    "    # Convert bounding box format from [x1, y1, x2, y2] to [x, y, w, h] x,y is the center of the box\n",
    "    y = torch.zeros_like(x) if isinstance(x, torch.Tensor) else np.zeros_like(x)\n",
    "\n",
    "    y[:, 0] = (x[:, 0] + x[:, 2]) / 2.0\n",
    "    y[:, 1] = (x[:, 1] + x[:, 3]) / 2.0\n",
    "    y[:, 2] = x[:, 2] - x[:, 0]\n",
    "    y[:, 3] = x[:, 3] - x[:, 1]\n",
    "    return y\n",
    "\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    # Convert bounding box format from [x, y, w, h] to [x1, y1, x2, y2]\n",
    "    y = torch.zeros_like(x) if isinstance(x, torch.Tensor) else np.zeros_like(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def bbox_iou(box1, box2, mode=\"xyxy\"):\n",
    "    \"\"\"\n",
    "    numpy version iou, and use for nms\n",
    "    \"\"\"\n",
    "    # Get the coordinates of bounding boxes\n",
    "\n",
    "    if mode == \"xyxy\":\n",
    "        # x1, y1, x2, y2 = box1\n",
    "        b1_x1, b1_y1, b1_x2, b1_y2 = box1[..., 0], box1[..., 1], box1[..., 2], box1[..., 3]\n",
    "        b2_x1, b2_y1, b2_x2, b2_y2 = box2[..., 0], box2[..., 1], box2[..., 2], box2[..., 3]\n",
    "    else:\n",
    "        # x, y, w, h = box1\n",
    "        b1_x1, b1_x2 = box1[..., 0] - box1[..., 2] / 2, box1[..., 0] + box1[..., 2] / 2\n",
    "        b1_y1, b1_y2 = box1[..., 1] - box1[..., 3] / 2, box1[..., 1] + box1[..., 3] / 2\n",
    "        b2_x1, b2_x2 = box2[..., 0] - box2[..., 2] / 2, box2[..., 0] + box2[..., 2] / 2\n",
    "        b2_y1, b2_y2 = box2[..., 1] - box2[..., 3] / 2, box2[..., 1] + box2[..., 3] / 2\n",
    "\n",
    "    # Intersection area\n",
    "    inter_area = np.maximum((np.minimum(b1_x2, b2_x2) - np.maximum(b1_x1, b2_x1)), 0.0) * \\\n",
    "                 np.maximum(np.minimum(b1_y2, b2_y2) - np.maximum(b1_y1, b2_y1), 0.0)\n",
    "\n",
    "    # Union Area\n",
    "    union_area = ((b1_x2 - b1_x1) * (b1_y2 - b1_y1) + 1e-16) + \\\n",
    "                 (b2_x2 - b2_x1) * (b2_y2 - b2_y1) - inter_area\n",
    "\n",
    "    return inter_area / union_area  # iou\n",
    "\n",
    "\n",
    "def iou_xywh_numpy(boxes1, boxes2):\n",
    "    \"\"\"\n",
    "    :param boxes1: boxes1和boxes2的shape可以不相同，但是需要满足广播机制\n",
    "    :param boxes2: 且需要保证最后一维为坐标维，以及坐标的存储结构为(x,y,w,h)，其中(x,y)是bbox的中心坐标\n",
    "    :return: 返回boxes1和boxes2的IOU，IOU的shape为boxes1和boxes2广播后的shape[:-1]\n",
    "    \"\"\"\n",
    "    boxes1 = np.array(boxes1)\n",
    "    boxes2 = np.array(boxes2)\n",
    "\n",
    "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
    "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "    print(boxes1[..., 0],boxes1[..., 1],boxes1[..., 2],boxes1[..., 3])\n",
    "\n",
    "    # 分别计算出boxes1和boxes2的左上角坐标、右下角坐标\n",
    "    # 存储结构为(xmin, ymin, xmax, ymax)，其中(xmin,ymin)是bbox的左上角坐标，(xmax,ymax)是bbox的右下角坐标\n",
    "    boxes1 = np.concatenate([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                             boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2 = np.concatenate([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                             boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    # 计算出boxes1与boxes1相交部分的左上角坐标、右下角坐标\n",
    "    left_up = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    # 因为两个boxes没有交集时，(right_down - left_up) < 0，所以maximum可以保证当两个boxes没有交集时，它们之间的iou为0\n",
    "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "    IOU = 1.0 * inter_area / union_area\n",
    "    return IOU\n",
    "\n",
    "\n",
    "def iou_xyxy_numpy(boxes1, boxes2):\n",
    "\n",
    "    boxes1 = np.array(boxes1)\n",
    "    boxes2 = np.array(boxes2)\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "    \n",
    "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "    IOU = 1.0 * inter_area / union_area\n",
    "    return IOU\n",
    "\n",
    "\n",
    "def iou_xyxy_torch(boxes1, boxes2):\n",
    "    \"\"\"\n",
    "    :param boxes1: boxes1和boxes2的shape可以不相同，但是需要满足广播机制，且需要是Tensor\n",
    "    :param boxes2: 且需要保证最后一维为坐标维，以及坐标的存储结构为(xmin, ymin, xmax, ymax)\n",
    "    :return: 返回boxes1和boxes2的IOU，IOU的shape为boxes1和boxes2广播后的shape[:-1]\n",
    "    \"\"\"\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    # 计算出boxes1与boxes1相交部分的左上角坐标、右下角坐标\n",
    "    left_up = torch.max(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = torch.min(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    # 因为两个boxes没有交集时，(right_down - left_up) < 0，所以maximum可以保证当两个boxes没有交集时，它们之间的iou为0\n",
    "    inter_section = torch.max(right_down - left_up, torch.zeros_like(right_down))\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "    IOU = 1.0 * inter_area / union_area\n",
    "    return IOU\n",
    "\n",
    "\n",
    "def iou_xywh_torch(boxes1, boxes2):\n",
    "    \"\"\"\n",
    "    :param boxes1: boxes1和boxes2的shape可以不相同，但是需要满足广播机制，且需要是Tensor\n",
    "    :param boxes2: 且需要保证最后一维为坐标维，以及坐标的存储结构为(x, y, w, h)\n",
    "    :return: 返回boxes1和boxes2的IOU，IOU的shape为boxes1和boxes2广播后的shape[:-1]\n",
    "    \"\"\"\n",
    "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
    "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "    # 分别计算出boxes1和boxes2的左上角坐标、右下角坐标\n",
    "    # 存储结构为(xmin, ymin, xmax, ymax)，其中(xmin,ymin)是bbox的左上角坐标，(xmax,ymax)是bbox的右下角坐标\n",
    "    boxes1 = torch.cat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], dim=-1)\n",
    "    boxes2 = torch.cat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], dim=-1)\n",
    "    # 计算出boxes1与boxes1相交部分的左上角坐标、右下角坐标\n",
    "    left_up = torch.max(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = torch.min(boxes1[..., 2:], boxes2[..., 2:])\n",
    "    # 因为两个boxes没有交集时，(right_down - left_up) < 0，所以maximum可以保证当两个boxes没有交集时，它们之间的iou为0\n",
    "    inter_section = torch.max(right_down - left_up, torch.zeros_like(right_down))\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "    IOU = 1.0 * inter_area / union_area\n",
    "\n",
    "    return IOU\n",
    "\n",
    "\n",
    "def nms(bboxes, score_threshold, iou_threshold, sigma=0.3, method='nms'):\n",
    "\n",
    "    classes_in_img = list(set(bboxes[:, 5].astype(np.int32)))\n",
    "    best_bboxes = []\n",
    "\n",
    "    for cls in classes_in_img:\n",
    "        cls_mask = (bboxes[:, 5].astype(np.int32) == cls)\n",
    "        cls_bboxes = bboxes[cls_mask]\n",
    "        while len(cls_bboxes) > 0:\n",
    "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
    "            best_bbox = cls_bboxes[max_ind]\n",
    "            best_bboxes.append(best_bbox)\n",
    "            cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
    "            iou = iou_xyxy_numpy(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
    "\n",
    "            weight = np.ones((len(iou),), dtype=np.float32)\n",
    "            iou_mask = iou > iou_threshold\n",
    "            weight[iou_mask] = 0.0\n",
    "            \n",
    "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
    "            score_mask = cls_bboxes[:, 4] > score_threshold\n",
    "            cls_bboxes = cls_bboxes[score_mask]\n",
    "    return np.array(best_bboxes)\n",
    "\n",
    "\n",
    "def Accuray_seg(y_pred, y_true):\n",
    "    return np.mean(y_pred == y_true)\n",
    "\n",
    "def Precision_seg(y_pred, y_true):\n",
    "    return np.sum((y_pred == 1) & (y_true == 1)) / np.sum(y_pred == 1)\n",
    "\n",
    "def Recall_seg(y_pred, y_true):\n",
    "    return np.sum((y_pred == 1) & (y_true == 1)) / np.sum(y_true == 1)\n",
    "\n",
    "def F1_seg(y_pred, y_true):\n",
    "    precision = Precision(y_pred, y_true)\n",
    "    recall = Recall(y_pred, y_true)\n",
    "    return 2*precision*recall/(precision+recall)\n",
    "\n",
    "\n",
    "def Sensitivity_seg(y_pred, y_true):\n",
    "    return np.sum((y_pred == 1) & (y_true == 1)) / np.sum(y_true == 1)\n",
    "\n",
    "def Specificity_seg(y_pred, y_true):\n",
    "    return np.sum((y_pred == 0) & (y_true == 0)) / np.sum(y_true == 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_seg(target,preds):\n",
    "    X = target.view(-1)\n",
    "    Y = preds.view(-1)\n",
    "    return 2*torch.mean(torch.mul(X,Y))/torch.mean(X+Y)\n",
    "\n",
    "\n",
    "def IoU_seg(target,preds):\n",
    "    X = target.view(-1)\n",
    "    Y = preds.view(-1)\n",
    "    return torch.mean(torch.mul(X,Y))/(torch.mean(X+Y)-torch.mean(torch.mul(X,Y)))\n",
    "\n",
    "def Accuracy_seg(target,preds):\n",
    "    X = target.view(-1)\n",
    "    Y = preds.view(-1)\n",
    "    X = X.cpu().numpy()\n",
    "    Y = Y.cpu().numpy()\n",
    "    TN, FP, FN, TP = confusion_matrix(X, Y).ravel()     \n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy =  (TP+TN)/(TP+FP+TN+FN)\n",
    "    return accuracy\n",
    "        \n",
    "def sensitivity_seg(target,preds):\n",
    "    X = target.view(-1)\n",
    "    Y = preds.view(-1)\n",
    "    X = X.numpy()\n",
    "    Y = Y.numpy()\n",
    "    TN, FP, FN, TP = confusion_matrix(X, Y).ravel()     \n",
    "    return TP/(TP+FN)\n",
    "\n",
    "def specificity_seg(target,preds):\n",
    "    X = target.view(-1)\n",
    "    Y = preds.view(-1)\n",
    "    X = X.cpu().numpy()\n",
    "    Y = Y.cpu().numpy()\n",
    "    TN, FP, FN, TP = confusion_matrix(X, Y).ravel()     \n",
    "    return TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nms(bboxes, iou_threshold):\n",
    "    classes_in_img = list(set(bboxes[:, 4].astype(np.int32)))\n",
    "\n",
    "    best_bboxes = []\n",
    "\n",
    "    for cls in classes_in_img:\n",
    "        cls_mask = (bboxes[:, 4].astype(np.int32) == cls)\n",
    "        cls_bboxes = bboxes[cls_mask]\n",
    "        while len(cls_bboxes) > 0:\n",
    "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
    "            best_bbox = cls_bboxes[max_ind]\n",
    "            best_bboxes.append(best_bbox)\n",
    "            cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
    "            iou = iou_xyxy_numpy(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
    "\n",
    "            weight = np.ones((len(iou),), dtype=np.float32)\n",
    "            iou_mask = iou > iou_threshold\n",
    "            weight[iou_mask] = 0.0\n",
    "            \n",
    "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
    "    return np.array(best_bboxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(572-388)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1960.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7*7*4*20/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*3*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(0.3750)\n",
      "tensor(0.)\n",
      "0.0\n",
      "tensor(0.)\n",
      "tensor(0.1282)\n",
      "tensor(0.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "pred_box_1 = np.array([10,50,20,20])\n",
    "pred_box_2 = np.array([40,10,40,30])\n",
    "gt_box_1 = np.array([40,60,40,20])\n",
    "gt_box_2 = np.array([15,60,15,10])\n",
    "\n",
    "pred_box_1 = torch.from_numpy(pred_box_1)\n",
    "pred_box_2 = torch.from_numpy(pred_box_2)\n",
    "gt_box_1 = torch.from_numpy(gt_box_1)\n",
    "gt_box_2 = torch.from_numpy(gt_box_2)\n",
    "\n",
    "\n",
    "print(IoU_bbox(pred_box_1,gt_box_1))\n",
    "print(IoU_bbox(pred_box_1,gt_box_2))\n",
    "print(IoU_bbox(pred_box_2,gt_box_1))\n",
    "print(IoU_bbox(pred_box_2,gt_box_2))\n",
    "\n",
    "print(iou_xywh_torch(pred_box_1,gt_box_1))\n",
    "print(iou_xywh_torch(pred_box_1,gt_box_2))\n",
    "print(iou_xywh_torch(pred_box_2,gt_box_1))\n",
    "print(iou_xywh_torch(pred_box_2,gt_box_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n",
      "0.0\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.2000)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "pred_box_1 = np.array([10,20,10,20])\n",
    "#pred_box_2 = np.array( [60,60,60,60])\n",
    "gt_box_1 = np.array([10,30,10,10])\n",
    "gt_box_2 = np.array( [60,60,60,60])\n",
    "\n",
    "pred_box_1 = torch.from_numpy(pred_box_1)\n",
    "#pred_box_2 = torch.from_numpy(pred_box_2)\n",
    "gt_box_1 = torch.from_numpy(gt_box_1)\n",
    "gt_box_2 = torch.from_numpy(gt_box_2)\n",
    "\n",
    "\n",
    "print(IoU_bbox(pred_box_1,gt_box_1))\n",
    "print(IoU_bbox(pred_box_1,gt_box_2))\n",
    "print(IoU_bbox(pred_box_2,gt_box_1))\n",
    "print(IoU_bbox(pred_box_2,gt_box_2))\n",
    "\n",
    "print(iou_xywh_torch(pred_box_1,gt_box_1))\n",
    "print(iou_xywh_torch(pred_box_1,gt_box_2))\n",
    "print(iou_xywh_torch(pred_box_2,gt_box_1))\n",
    "print(iou_xywh_torch(pred_box_2,gt_box_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 60.0000,  60.0000,  60.0000,  60.0000,   0.9000],\n",
      "        [120.0000, 120.0000,  30.0000,  30.0000,   0.7000],\n",
      "        [ 65.0000,  65.0000,  50.0000,  50.0000,   0.4000],\n",
      "        [125.0000, 120.0000,  25.0000,  30.0000,   0.0000]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "B0 = np.array([65,65,50,50,0.4])\n",
    "B1 = np.array([125,120,25,30,0.6])\n",
    "B2 = np.array([60,60,60,60,0.9])\n",
    "B3 = np.array([120,120,30,30,0.7])\n",
    "\n",
    "B0 = torch.from_numpy(B0)\n",
    "B1 = torch.from_numpy(B1)\n",
    "B2 = torch.from_numpy(B2)\n",
    "B3 = torch.from_numpy(B3)\n",
    "\n",
    "\n",
    "bboxes = torch.stack([B0,B1,B2,B3],dim=0)\n",
    "bboxes = x1y1wh_to_x1y1x2y2(bboxes)\n",
    "\n",
    "bboxes = bboxes.numpy()\n",
    "\n",
    "bboxes_out = nms(bboxes, iou_threshold=0.7)\n",
    "\n",
    "bboxes_out = torch.from_numpy(bboxes_out)\n",
    "bboxes_out = x1y1x2y2_to_x1y1wh(bboxes_out)\n",
    "\n",
    "print(bboxes_out)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
